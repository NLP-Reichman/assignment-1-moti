{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Set up"
      ],
      "metadata": {
        "id": "FECp14-d_F2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NLP-Reichman/assignment_1.git\n",
        "!mv assignment_1/data data\n",
        "!rm assignment_1/ -r"
      ],
      "metadata": {
        "id": "za-DgcYB_IQx",
        "outputId": "4f1bb563-c548-4cd4-9b36-aae8f08db627",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'assignment_1'...\n",
            "remote: Enumerating objects: 150, done.\u001b[K\n",
            "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
            "remote: Compressing objects: 100% (22/22), done.\u001b[K\n",
            "remote: Total 150 (delta 35), reused 22 (delta 22), pack-reused 106\u001b[K\n",
            "Receiving objects: 100% (150/150), 6.79 MiB | 13.54 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction\n",
        "In this assignment you will be creating tools for learning and testing language models. The corpora that you will be working with are lists of tweets in 8 different languages that use the Latin script. The data is provided either formatted as CSV or as JSON, for your convenience. The end goal is to write a set of tools that can detect the language of a given tweet.\n",
        "The relevant files are under the data folder:\n",
        "\n",
        "- en.csv (or the equivalent JSON file)\n",
        "- es.csv (or the equivalent JSON file)\n",
        "- fr.csv (or the equivalent JSON file)\n",
        "- in.csv (or the equivalent JSON file)\n",
        "- it.csv (or the equivalent JSON file)\n",
        "- nl.csv (or the equivalent JSON file)\n",
        "- pt.csv (or the equivalent JSON file)\n",
        "- tl.csv (or the equivalent JSON file)"
      ],
      "metadata": {
        "id": "0i2bOXTB8Dvc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1u1qR7iaq_GU"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from google.colab import files\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation"
      ],
      "metadata": {
        "id": "IHN0tWTurwkN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1\n",
        "Implement the function *preprocess* that iterates over all the data files and creates a single vocabulary, containing all the tokens in the data. Our token definition is a single UTF-8 encoded character. So, the vocabulary list is a simple Python list of all the characters that you see at least once in the data.\n",
        "\n",
        "Note - do NOT lowercase the sentences in whi HW."
      ],
      "metadata": {
        "id": "i56aKA0K8adr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess() -> list[str]:\n",
        "  '''\n",
        "  Return a list of characters, representing the shared vocabulary of all languages\n",
        "  '''\n",
        "\n",
        "  import glob\n",
        "\n",
        "  csv_files = glob.glob('data/*.csv')\n",
        "\n",
        "  # Initialize an empty DataFrame to contain all the data\n",
        "  all_csv_df = pd.DataFrame()\n",
        "\n",
        "  # concat all *.csv\n",
        "  for filename in csv_files:\n",
        "    #print(f\" filename = {filename}\\n\")\n",
        "    df = pd.read_csv(filename)\n",
        "    all_csv_df = pd.concat([all_csv_df, df], ignore_index=True)\n",
        "\n",
        "  # get all the tweets\n",
        "  all_tweets = all_csv_df['tweet_text'].values\n",
        "\n",
        "  # convert the tweets from strings into a joint list of characters\n",
        "  all_chars = []\n",
        "  for t in range(len(all_tweets)):\n",
        "    tweet = list(all_tweets[t])\n",
        "    for letter in tweet:\n",
        "      all_chars.append(letter)\n",
        "\n",
        "  # add <start> & <end> keys\n",
        "  s_and_e = ['<s>', '<e>']\n",
        "  for t in range(len(s_and_e)):\n",
        "    all_chars.append(s_and_e[t])\n",
        "\n",
        "  # get the unique\n",
        "  vocabulary = set(all_chars)\n",
        "\n",
        "  return set(vocabulary)"
      ],
      "metadata": {
        "id": "ws_5u7vRrg0o"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(preprocess())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYgAElSeX4yh",
        "outputId": "0304ef25-f6cd-4881-a639-cbf8bd588450"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1804"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2\n",
        "Implement the function *lm* that generates a language model from a textual corpus. The function should return a dictionary (representing a model) where the keys are all the relevant *n*-1 sequences, and the values are dictionaries with the *n*_th tokens and their corresponding probabilities to occur. For example, for a trigram model (tokens are characters), it should look something like:\n",
        "\n",
        "{ \"ab\":{\"c\":0.5, \"b\":0.25, \"d\":0.25}, \"ca\":{\"a\":0.2, \"b\":0.7, \"d\":0.1} }\n",
        "\n",
        "which means for example that after the sequence \"ab\", there is a 0.5 chance that \"c\" will appear, 0.25 for \"b\" to appear and 0.25 for \"d\" to appear.\n",
        "\n",
        "Note - You should think how to add the add_one smoothing information to the dictionary and implement it."
      ],
      "metadata": {
        "id": "tpjtwHW08jyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lm(lang: str, n: int, smoothed: bool = False) -> dict[str, dict[str, float]]:\n",
        "    '''\n",
        "    Return a language model for the given lang and n-gram (n), with an option for smoothing.\n",
        "    :param lang: the language of the model\n",
        "    :param n: the n_gram value\n",
        "    :param smoothed: boolean indicating whether to apply smoothing\n",
        "    :return: a dictionary where the keys are n-1 grams and the values are dictionaries\n",
        "    '''\n",
        "    from collections import Counter, defaultdict\n",
        "\n",
        "    # get all tweets of the chosen language\n",
        "    language = lang\n",
        "    # print(f\" lm language = {language}\\n\")\n",
        "    file_path_and_name = ''.join(['data/', language, '.csv'])\n",
        "    df = pd.read_csv(file_path_and_name)\n",
        "    tweets = df['tweet_text'].values\n",
        "    V = len(preprocess()) # vocabulary length\n",
        "\n",
        "    # convert the tweets from strings into corpus\n",
        "    corpus = []\n",
        "    for t in range(len(tweets)):\n",
        "      # pad every tweet with n-1 start tokens and 1 end token\n",
        "      for s in range(n):\n",
        "        corpus.append('<s>')\n",
        "\n",
        "      tweet = list(tweets[t])\n",
        "      for letter in tweet:\n",
        "        corpus.append(letter)\n",
        "\n",
        "      corpus.append('<e>')\n",
        "\n",
        "    # Count the frequency of each and every n-gram in the corpus\n",
        "    n_gram_counter = defaultdict(Counter) # init counters\n",
        "\n",
        "    for c in range(n-1, len(corpus)):\n",
        "        context = ''.join(corpus[c-n+1:c])\n",
        "        token = corpus[c]\n",
        "        n_gram_counter[context][token] += 1\n",
        "\n",
        "    probs = defaultdict(Counter)\n",
        "    for context, tokens in n_gram_counter.items():\n",
        "      context_counter = sum(tokens.values())\n",
        "\n",
        "      for token, count in tokens.items():\n",
        "        if smoothed == False:\n",
        "          probs[context][token] = count / context_counter\n",
        "        else: # perform smoothing\n",
        "          probs[context][token] = (count + 1) / (context_counter + V)\n",
        "\n",
        "    # create a list of the unique dictionary keys taken from the corpus.\n",
        "    # Note: the <e> key must not be included in the output dictionary\n",
        "    all_context = []\n",
        "    for c in range(n-1, len(corpus)):\n",
        "      context_list = corpus[c-n+1:c]\n",
        "      end_token_in_context = sum([int(char == '<e>') for char in context_list]) > 0\n",
        "\n",
        "      if end_token_in_context == False:\n",
        "        all_context.append(''.join(context_list))\n",
        "\n",
        "    context_keys = list(set(all_context))\n",
        "\n",
        "    # create the output dictionary\n",
        "    n_gram_dict = {}\n",
        "    for k in range(len(context_keys)):\n",
        "      n_gram_dict.update({context_keys[k]: dict(probs[context_keys[k]])})\n",
        "\n",
        "    # add the unknown token\n",
        "    if smoothed == True:\n",
        "      n_gram_dict.update({'<unk>': 1/V})\n",
        "\n",
        "    return dict(n_gram_dict)"
      ],
      "metadata": {
        "id": "C9AdFAiS8qqA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "        'english_2_gram_length': len(lm('en', 2, True)),\n",
        "        'english_3_gram_length': len(lm('en', 3, True)),\n",
        "        'french_3_gram_length': len(lm('fr', 3, True)),\n",
        "        'spanish_3_gram_length': len(lm('es', 3, True)),\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myea4UsLDnSe",
        "outputId": "bec987b9-949b-4574-a9a6-a87ba2d5eea2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'english_2_gram_length': 748,\n",
              " 'english_3_gram_length': 8239,\n",
              " 'french_3_gram_length': 8286,\n",
              " 'spanish_3_gram_length': 8469}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3\n",
        "Implement the function *eval* that returns the perplexity of a model (dictionary) running over the data file of the given target language."
      ],
      "metadata": {
        "id": "xwZnk7Ke8rW5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model: dict, target_lang: str, n: int) -> float:\n",
        "  '''\n",
        "  Return the perplexity value calculated over applying the model on the text file\n",
        "  of the target_lang language.\n",
        "  :param model: the language model\n",
        "  :param target_lang: the target language\n",
        "  :param n: The n-gram of the model\n",
        "  :return: the perplexity value\n",
        "  '''\n",
        "  import numpy as np\n",
        "\n",
        "  # Get all tweets of the chosen language\n",
        "  language = target_lang\n",
        "  # print(f\" target language = {language}\\n\")\n",
        "  file_path_and_name = ''.join(['data/', language, '.csv'])\n",
        "  df = pd.read_csv(file_path_and_name)\n",
        "  tweets = df['tweet_text'].values\n",
        "\n",
        "  # convert the tweets from strings into corpus\n",
        "  corpus = []\n",
        "  for t in range(len(tweets)):\n",
        "    # Pad every tweet with n-1 start tokens and 1 end token\n",
        "    for s in range(n):\n",
        "      corpus.append('<s>')\n",
        "\n",
        "    tweet = list(tweets[t])\n",
        "    for letter in tweet:\n",
        "      corpus.append(letter)\n",
        "\n",
        "    corpus.append('<e>')\n",
        "\n",
        "  # number of unique elements in the corpus\n",
        "  V = len(preprocess()) # vocabulary length\n",
        "  prob_unknwn = 1/V\n",
        "\n",
        "  # Initialize variables\n",
        "  sum_log_prob = 0.0\n",
        "  n_tokens = len(corpus)\n",
        "\n",
        "  # Calculate cross-entropy\n",
        "  for c in range(n-1, n_tokens):\n",
        "      context = ''.join(corpus[c-n+1:c])\n",
        "      token = corpus[c]\n",
        "      # extract probability and add up its log2 value\n",
        "      # if it's an unknown token then use default probability (prob_unknwn)\n",
        "      try:\n",
        "        prob = model[context][token]\n",
        "      except:\n",
        "        prob = prob_unknwn\n",
        "\n",
        "      sum_log_prob -= np.log2(prob)\n",
        "\n",
        "  # Compute perplexity\n",
        "  cross_entropy = sum_log_prob / n_tokens\n",
        "  perplexity = np.power(2, cross_entropy)\n",
        "\n",
        "  return perplexity"
      ],
      "metadata": {
        "id": "ef-EglxXrmk2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "        'en_en': eval(lm('en', 3, True), 'en', 3),\n",
        "        'en_fr': eval(lm('en', 3, True), 'fr', 3),\n",
        "        'en_tl': eval(lm('en', 3, True), 'tl', 3),\n",
        "        'en_nl': eval(lm('en', 3, True), 'nl', 3),\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK4oIXh7DyfJ",
        "outputId": "e8be37e2-6b23-40fa-f690-10039a54e193"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'en_en': 28.578718604332522,\n",
              " 'en_fr': 59.52748418449823,\n",
              " 'en_tl': 72.93649027000441,\n",
              " 'en_nl': 63.101789298831456}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4\n",
        "Implement the *match* function that calls *eval* using a specific value of *n* for every possible language pair among the languages we have data for. You should call *eval* for every language pair four times, with each call assign a different value for *n* (1-4). Each language pair is composed of the source language and the target language. Before you make the call, you need to call the *lm* function to create the language model for the source language. Then you can call *eval* with the language model and the target language. The function should return a pandas DataFrame with the following four columns: *source_lang*, *target_lang*, *n*, *perplexity*. The values for the first two columns are the two-letter language codes. The value for *n* is the *n* you use for generating the specific perplexity values which you should store in the forth column."
      ],
      "metadata": {
        "id": "9ZYVc7hB84LP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def match() -> pd.DataFrame:\n",
        "  '''\n",
        "  Return a DataFrame containing one line per every language pair and n_gram.\n",
        "  Each line will contain the perplexity calculated when applying the language model\n",
        "  of the source language on the text of the target language.\n",
        "  :return: a DataFrame containing the perplexity values\n",
        "  '''\n",
        "  n_gram_max = 4\n",
        "  languages = ['en', 'es', 'fr', 'in', 'it', 'nl', 'pt', 'tl']\n",
        "  n_languages = len(languages)\n",
        "  match_df = pd.DataFrame(columns=['source', 'target', 'n', 'perplexity'])\n",
        "  counter = 0\n",
        "\n",
        "  for n_gram in range(1, n_gram_max+1):\n",
        "    print(f\"match for n-gram = {n_gram}\\n\")\n",
        "    for source in languages:\n",
        "      language_model = lm(source, n_gram)\n",
        "\n",
        "      for target in languages:\n",
        "        perplexity = eval(language_model, target, n_gram)\n",
        "        match_df.loc[counter] = [source, target, n_gram, perplexity]\n",
        "        counter += 1\n",
        "\n",
        "  return match_df"
      ],
      "metadata": {
        "id": "16ew9aZWroPC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match_df = match()\n",
        "match_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "XcGZE7jWcajl",
        "outputId": "c25697b5-78e4-4df1-c601-5db06ede48ef"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "match for n-gram = 1\n",
            "\n",
            "match for n-gram = 2\n",
            "\n",
            "match for n-gram = 3\n",
            "\n",
            "match for n-gram = 4\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    source target  n  perplexity\n",
              "0       en     en  1   38.577504\n",
              "1       en     es  1   39.703161\n",
              "2       en     fr  1   41.192687\n",
              "3       en     in  1   41.236615\n",
              "4       en     it  1   39.629555\n",
              "..     ...    ... ..         ...\n",
              "251     tl     in  4   51.458478\n",
              "252     tl     it  4   48.662568\n",
              "253     tl     nl  4   73.317033\n",
              "254     tl     pt  4   57.697890\n",
              "255     tl     tl  4    5.381476\n",
              "\n",
              "[256 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a30f424-faa1-4bf4-aa13-3702243dc93b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>n</th>\n",
              "      <th>perplexity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>en</td>\n",
              "      <td>en</td>\n",
              "      <td>1</td>\n",
              "      <td>38.577504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>en</td>\n",
              "      <td>es</td>\n",
              "      <td>1</td>\n",
              "      <td>39.703161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>en</td>\n",
              "      <td>fr</td>\n",
              "      <td>1</td>\n",
              "      <td>41.192687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>en</td>\n",
              "      <td>in</td>\n",
              "      <td>1</td>\n",
              "      <td>41.236615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>en</td>\n",
              "      <td>it</td>\n",
              "      <td>1</td>\n",
              "      <td>39.629555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>tl</td>\n",
              "      <td>in</td>\n",
              "      <td>4</td>\n",
              "      <td>51.458478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>tl</td>\n",
              "      <td>it</td>\n",
              "      <td>4</td>\n",
              "      <td>48.662568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>tl</td>\n",
              "      <td>nl</td>\n",
              "      <td>4</td>\n",
              "      <td>73.317033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>tl</td>\n",
              "      <td>pt</td>\n",
              "      <td>4</td>\n",
              "      <td>57.697890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>tl</td>\n",
              "      <td>tl</td>\n",
              "      <td>4</td>\n",
              "      <td>5.381476</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>256 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a30f424-faa1-4bf4-aa13-3702243dc93b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8a30f424-faa1-4bf4-aa13-3702243dc93b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8a30f424-faa1-4bf4-aa13-3702243dc93b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-33fb3e9b-e085-4e0d-a7dc-b880dc6850e3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-33fb3e9b-e085-4e0d-a7dc-b880dc6850e3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-33fb3e9b-e085-4e0d-a7dc-b880dc6850e3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bbd3e80c-25cd-4ecc-b612-9291ee9b4811\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('match_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bbd3e80c-25cd-4ecc-b612-9291ee9b4811 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('match_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "match_df",
              "summary": "{\n  \"name\": \"match_df\",\n  \"rows\": 256,\n  \"fields\": [\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"es\",\n          \"nl\",\n          \"en\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"es\",\n          \"nl\",\n          \"en\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"n\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"perplexity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.830207474435156,\n        \"min\": 5.307467175794195,\n        \"max\": 121.7155458605317,\n        \"num_unique_values\": 256,\n        \"samples\": [\n          5.5912984087604,\n          41.092301387520784,\n          29.474302679611657\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5\n",
        "Implement the *generate* function which takes a language code, *n*, the prompt (the starting text), the number of tokens to generate, and *r*, which is the random seed for any randomized action you plan to take in your implementation. The function should start generating tokens, one by one, using the language model of the given source language and *n*. The prompt should be used as a starting point for aligning on the probabilities to be used for generating the next token.\n",
        "\n",
        "Note - The generation of the next token should be from the LM's distribution.\n",
        "\n",
        "Note #2 - if you use an <END> token in your vocabulary, then once the <END> token is generated by the model, you should stop generating text."
      ],
      "metadata": {
        "id": "pAQoR0dH9C3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(lang: str, n: int, prompt: str, number_of_tokens: int, r: int) -> str:\n",
        "  '''\n",
        "  Generate text in the given language using the given parameters.\n",
        "  :param lang: the language of the model\n",
        "  :param n: the n_gram value\n",
        "  :param prompt: the prompt to start the generation\n",
        "  :param number_of_tokens: the number of tokens to generate\n",
        "  :param r: the random seed to use\n",
        "  '''\n",
        "  import random\n",
        "  random.seed(r)\n",
        "\n",
        "  # give up to 10 chances to generate a token different from <e>\n",
        "  e_iterations = 10\n",
        "\n",
        "  # generate the model\n",
        "  model = lm(lang, n, smoothed=False)\n",
        "\n",
        "  # tokenize the prompt\n",
        "  tokenized_prompt = []\n",
        "  prompt_head = list(prompt)\n",
        "  for letter in prompt_head:\n",
        "    tokenized_prompt.append(letter)\n",
        "  #print(f\"tokenized_prompt init = {tokenized_prompt}\\n\")\n",
        "\n",
        "  for t in range(number_of_tokens):\n",
        "    if n == 1:\n",
        "      # it's a uni-gram -> there is a single context\n",
        "      context = list(model.keys())[0]\n",
        "\n",
        "    elif len(tokenized_prompt) >= n-1:\n",
        "      # there is enough tokens to proceed\n",
        "      #print(f\"tokenized_prompt n-1 = {tokenized_prompt[-(n-1):]}, type={type(tokenized_prompt[-(n-1):])}, len={len(tokenized_prompt[-(n-1):])}\\n\")\n",
        "      context = ''.join(tokenized_prompt[-(n-1):])\n",
        "\n",
        "    else:\n",
        "      # we are short!\n",
        "      # print a warning and pad it with starting spaces\n",
        "      context = ''.join([' ']*(n-1-len(tokenized_prompt)) + tokenized_prompt)\n",
        "      print(f\"too short context = {context} -> padding with spaces\\n\")\n",
        "\n",
        "    # check if the context key is included in the model, otherwise pick uniformly from the model\n",
        "    if context not in model:\n",
        "      # context is not included in our model -> pick randomly\n",
        "      context = ''.join(random.choices(list(model.keys()), k=1))\n",
        "      #print(f\"pick key = {context}, type={type(context)}, len={len(context)}\\n\")\n",
        "\n",
        "    # get the options from our model according to the context\n",
        "    next_token_options = model[context]\n",
        "\n",
        "    # pick a token and make sure it's not an <e> token (avoid getting <e> key since it's not included in the model)\n",
        "    for e in range(e_iterations):\n",
        "      next_token = ''.join(random.choices(list(next_token_options.keys()), weights=next_token_options.values(), k=1))\n",
        "      if next_token != '<e>':\n",
        "        break\n",
        "\n",
        "    if next_token == '<e>':\n",
        "        next_token = ' '\n",
        "\n",
        "    # add the chosen token\n",
        "    tokenized_prompt.append(next_token)\n",
        "\n",
        "  # \"glue\" it all together\n",
        "  generated_text = ''.join(tokenized_prompt)\n",
        "\n",
        "  return generated_text"
      ],
      "metadata": {
        "id": "CpCm24-RrpuA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1L82Rv4q3yqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "        'english_1_gram': generate('en', 1, \"I\", 20, 5),\n",
        "        'english_2_gram': generate('en', 2, \"I am\", 20, 5),\n",
        "        'english_3_gram': generate('en', 3, \"I am\", 20, 5),\n",
        "        'english_4_gram': generate('en', 4, \"I Love\", 20, 5),\n",
        "        'spanish_2_gram': generate('es', 2, \"Soy\", 20, 5),\n",
        "        'spanish_3_gram': generate('es', 3, \"Soy\", 20, 5),\n",
        "        'french_2_gram': generate('fr', 2, \"Je suis\", 20, 5),\n",
        "        'french_3_gram': generate('fr', 3, \"Je suis\", 20, 5),\n",
        "    }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzI5_9Dlr-4q",
        "outputId": "f674c192-7014-4dc5-8dd1-774da6384223"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'english_1_gram': 'ItpgLpITeLhF eBstRlo2',\n",
              " 'english_2_gram': 'I amoulpeginShmee bie ae',\n",
              " 'english_3_gram': 'I amit: Lynmkm ways. htt',\n",
              " 'english_4_gram': 'I Love gifts @OndMade a no',\n",
              " 'spanish_2_gram': 'Soycalíodenyegucosie ew',\n",
              " 'spanish_3_gram': 'Soy orbershagang https:',\n",
              " 'french_2_gram': 'Je suis:/opapropades tprisl',\n",
              " 'french_3_gram': 'Je suis tunes #ACTURSICALU '}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6\n",
        "Play with your generate function, try to generate different texts in different language and various values of *n*. No need to submit anything of that."
      ],
      "metadata": {
        "id": "eUWX8Ugu9INH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVmdZAMM-8RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sZN-ljLG-8I9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "q2jNlDISr9aL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the content of the **tests.py** file from the repo and paste below. This will create the results.json file and download it to your machine."
      ],
      "metadata": {
        "id": "uv48OCT_sIYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####################\n",
        "# PLACE TESTS HERE #\n",
        "\n",
        "####################\n",
        "def test_preprocess():\n",
        "    return {\n",
        "        'vocab_length': len(preprocess()),\n",
        "    }\n",
        "\n",
        "def test_lm():\n",
        "    return {\n",
        "        'english_2_gram_length': len(lm('en', 2, True)),\n",
        "        'english_3_gram_length': len(lm('en', 3, True)),\n",
        "        'french_3_gram_length': len(lm('fr', 3, True)),\n",
        "        'spanish_3_gram_length': len(lm('es', 3, True)),\n",
        "    }\n",
        "\n",
        "def test_eval():\n",
        "    return {\n",
        "        'en_en': eval(lm('en', 3, True), 'en', 3),\n",
        "        'en_fr': eval(lm('en', 3, True), 'fr', 3),\n",
        "        'en_tl': eval(lm('en', 3, True), 'tl', 3),\n",
        "        'en_nl': eval(lm('en', 3, True), 'nl', 3),\n",
        "    }\n",
        "\n",
        "def test_match():\n",
        "    df = match()\n",
        "    return {\n",
        "        'en_en_3': df[(df['source'] == 'en') & (df['target'] == 'en') & (df['n'] == 3)]['perplexity'].values[0],\n",
        "        'en_tl_3': df[(df['source'] == 'en') & (df['target'] == 'tl') & (df['n'] == 3)]['perplexity'].values[0],\n",
        "        'en_nl_3': df[(df['source'] == 'en') & (df['target'] == 'nl') & (df['n'] == 3)]['perplexity'].values[0],\n",
        "    }\n",
        "\n",
        "def test_generate():\n",
        "    return {\n",
        "        'english_1_gram': generate('en', 1, \"I\", 20, 5),\n",
        "        'english_2_gram': generate('en', 2, \"I am\", 20, 5),\n",
        "        'english_3_gram': generate('en', 3, \"I am\", 20, 5),\n",
        "        'english_4_gram': generate('en', 4, \"I Love\", 20, 5),\n",
        "        'spanish_2_gram': generate('es', 2, \"Soy\", 20, 5),\n",
        "        'spanish_3_gram': generate('es', 3, \"Soy\", 20, 5),\n",
        "        'french_2_gram': generate('fr', 2, \"Je suis\", 20, 5),\n",
        "        'french_3_gram': generate('fr', 3, \"Je suis\", 20, 5),\n",
        "    }\n",
        "\n",
        "TESTS = [test_preprocess, test_lm, test_eval, test_match, test_generate]\n",
        "\n",
        "# Run tests and save results\n",
        "res = {}\n",
        "for test in TESTS:\n",
        "    try:\n",
        "        cur_res = test()\n",
        "        res.update({test.__name__: cur_res})\n",
        "    except Exception as e:\n",
        "        res.update({test.__name__: repr(e)})\n",
        "\n",
        "with open('results.json', 'w') as f:\n",
        "    json.dump(res, f, indent=2)\n",
        "\n",
        "# Download the results.json file\n",
        "files.download('results.json')"
      ],
      "metadata": {
        "id": "JZTlc2ieruqq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "6b9059d8-122e-4b5f-ed1b-765d6f1cde07"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "match for n-gram = 1\n",
            "\n",
            "match for n-gram = 2\n",
            "\n",
            "match for n-gram = 3\n",
            "\n",
            "match for n-gram = 4\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b841d2fb-fa90-427b-be89-bd52e0688dc9\", \"results.json\", 920)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the local files, results.json should be there now and\n",
        "# also downloaded to your local machine\n",
        "!ls -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCksAA6RisRQ",
        "outputId": "48521290-7b08-48c4-a23d-6ca5fad5054a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12\n",
            "drwxr-xr-x 2 root root 4096 Apr 20 20:15 data\n",
            "-rw-r--r-- 1 root root  920 Apr 20 20:30 results.json\n",
            "drwxr-xr-x 1 root root 4096 Apr 18 13:25 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## check results.json"
      ],
      "metadata": {
        "id": "QB5pOwOSGiYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_preprocess(results):\n",
        "    if results[\"vocab_length\"] != 1804:\n",
        "        return f\"Vocab length is {results['vocab_length']}, expected 1804\"\n",
        "    return 1\n",
        "\n",
        "def test_lm(results):\n",
        "    if results[\"english_2_gram_length\"] != 748:\n",
        "        return f\"English 2-gram length is {results['english_2_gram_length']}, expected 748\"\n",
        "    if results[\"english_3_gram_length\"] != 8239:\n",
        "        return f\"English 3-gram length is {results['english_3_gram_length']}, expected 8239\"\n",
        "    if results[\"french_3_gram_length\"] != 8286:\n",
        "        return f\"French 3-gram length is {results['french_3_gram_length']}, expected 8286\"\n",
        "    if results[\"spanish_3_gram_length\"] != 8469:\n",
        "        return f\"Spanish 3-gram length is {results['spanish_3_gram_length']}, expected 8469\"\n",
        "    return 1\n",
        "\n",
        "def relative_difference(expected, actual):\n",
        "    \"\"\"Calculate the relative difference between expected and actual values.\"\"\"\n",
        "    return abs(expected - actual) / expected\n",
        "\n",
        "def test_eval(results):\n",
        "    perplexity_en_on_en = float(results[\"en_en\"])\n",
        "    perplexity_en_on_fr = float(results[\"en_fr\"])\n",
        "    perplexity_en_on_tl = float(results[\"en_tl\"])\n",
        "    perplexity_en_on_nl = float(results[\"en_nl\"])\n",
        "\n",
        "    perplexities = [\n",
        "        perplexity_en_on_en,\n",
        "        perplexity_en_on_fr,\n",
        "        perplexity_en_on_tl,\n",
        "        perplexity_en_on_nl\n",
        "    ]\n",
        "\n",
        "    if min(perplexities) != perplexity_en_on_en:\n",
        "        return f\"English model should perform best on English text. Results: {results}\"\n",
        "\n",
        "    if not (perplexity_en_on_en <= perplexity_en_on_fr <= max(perplexity_en_on_tl, perplexity_en_on_nl)):\n",
        "        return f\"Expected increasing perplexity from English to other languages. Results: {results}\"\n",
        "\n",
        "    return 1\n",
        "\n",
        "\n",
        "def test_match(results):\n",
        "    perplexity_en_on_en = int(results[\"en_en_3\"])\n",
        "    perplexity_en_on_tl = int(results[\"en_tl_3\"])\n",
        "    perplexity_en_on_nl = int(results[\"en_nl_3\"])\n",
        "\n",
        "    perplexities = [\n",
        "        perplexity_en_on_en,\n",
        "        perplexity_en_on_tl,\n",
        "        perplexity_en_on_nl\n",
        "    ]\n",
        "\n",
        "    if min(perplexities) != perplexity_en_on_en:\n",
        "        return f\"English model should perform best on English text. Results: {results}\"\n",
        "\n",
        "    if not (perplexity_en_on_en <= max(perplexity_en_on_tl, perplexity_en_on_nl)):\n",
        "        return f\"Expected increasing perplexity from English to other languages. Results: {results}\"\n",
        "\n",
        "    return 1\n",
        "\n",
        "\n",
        "def test_generate(results):\n",
        "    if not results[\"english_2_gram\"].startswith(\"I am\"):\n",
        "        return f\"English 2-gram does not start with 'I am', but with {results['english_2_gram']}\"\n",
        "    if not results[\"french_3_gram\"].startswith(\"Je suis\"):\n",
        "        return f\"French 3-gram does not start with 'Je suis', but with {results['french_3_gram']}\"\n",
        "    return 1\n",
        "\n",
        "\n",
        "# Read results.json\n",
        "with open('results.json', 'r') as f:\n",
        "    results = json.load(f)\n",
        "\n",
        "# Initialize the result variable\n",
        "result = None\n",
        "\n",
        "# Switch between the tests\n",
        "result1 = test_preprocess(results[\"test_preprocess\"])\n",
        "print(result1)\n",
        "result2 = test_lm(results[\"test_lm\"])\n",
        "print(result2)\n",
        "result3 = test_eval(results[\"test_eval\"])\n",
        "print(result3)\n",
        "result4 = test_match(results[\"test_match\"])\n",
        "print(result4)\n",
        "result5 = test_generate(results[\"test_generate\"])\n",
        "print(result5)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uMSfgUtuiux0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa46c962-433b-492f-d4cf-3d780bbf3009"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "1\n",
            "1\n",
            "1\n",
            "1\n"
          ]
        }
      ]
    }
  ]
}